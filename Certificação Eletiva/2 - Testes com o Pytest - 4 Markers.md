[[2 - Testes com o Pytest]]

OsÂ _markers_Â (marcadores) noÂ _Pytest_Â sÃ£o uma forma de marcar testes com atributos especÃ­ficos que podem ser usados para executar, filtrar ou pular testes. Os marcadores podem ser definidos usando a sintaxeÂ `@pytest.mark.nome_do_marker`Â no cÃ³digo de teste.

Para criar seu prÃ³prio marcador, basta criar uma funÃ§Ã£o que tenha como argumento um objeto de tipo pytest.mark. Por exemplo, para criar um marcador chamado â€œslowâ€ dentro de um arquivoÂ `markers_test.py`, vocÃª pode definir a seguinte funÃ§Ã£o em um arquivo de teste:

```python
import time

import pytest


@pytest.mark.slow
def test_slow_marker():
    time.sleep(4)

```

VocÃª pode executar o comandoÂ `pytest -m MARKEXPR`, no qualÂ **MARKEXPR**Â Ã© uma expressÃ£o que adiciona ou remove a seleÃ§Ã£o de um ou mais marcadores. Por exemplo, ao rodarÂ `pytest -m 'not slow' -vv`Â sÃ£o executados todos os testes, menos os marcados comoÂ _slow_.

O resultado serÃ¡ algo como isso aqui:

Copiar

```text
================================================= test session starts =================================================
platform darwin -- Python 3.11.0, pytest-7.3.1, pluggy-1.0.0
collected 8 items / 1 deselected / 7 selected                                                                         

a_test.py::test_a_simple_test PASSED                                                                            [ 14%]
a_test.py::test_sum PASSED                                                                                      [ 28%]
another_test.py::test_list_item_multiply PASSED                                                                 [ 42%]
fixtures_test.py::test_print_to_stdout PASSED                                                                   [ 57%]
fixtures_test.py::test_error_to_stderr PASSED                                                                   [ 71%]
fixtures_test.py::test_my_function PASSED                                                                       [ 85%]
fixtures_test.py::test_generate_output PASSED                                                                   [100%]

================================================== warnings summary ===================================================
markers_test.py:6
  ./pytest_app/markers_test.py:6: PytestUnknownMarkWarning: Unknown pytest.mark.slow - is this a typo?
    You can register custom marks to avoid this warning
    for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.slow

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
===================================== 7 passed, 1 deselected, 1 warning in 0.02s ======================================
```

Ã‰ interessante observar que temos um warning, pois criamos um marcador e nÃ£o informamos aoÂ _Pytest_Â que ele existe. Para corrigir isso, vocÃª pode adicionar o seguinte cÃ³digo ao arquivoÂ `conftest.py`:

Copiar

```python
def pytest_configure(config):
    config.addinivalue_line(
        "markers", "slow: marks tests as slow"
    )
```

## Markers built-in

Assim como as fixtures, oÂ _Pytest_Â jÃ¡ traz alguns marcadores embutidos. A seguir veremos dois deles!

### Skip

O marcadorÂ `skip`Â serve para pular um teste especÃ­fico. Ele pode ser Ãºtil, por exemplo, em uma situaÃ§Ã£o em que, por alguns dias, um sistema do qual seu cÃ³digo depende estÃ¡ indisponÃ­vel. A suÃ­te de testes pode quebrar por isso, mas vocÃª nÃ£o quer apagar os testes. Portanto, pular esses testes que estÃ£o momentaneamente quebrando pode ser a soluÃ§Ã£o.

Mais Ãºtil que oÂ `skip`Â Ã© a sua variante mais especÃ­ficaÂ `skipif`, que pula um teste a depender de uma condiÃ§Ã£o. Por exemplo, se um teste deve rodar somente em Windows e outro somente em Linux, vocÃª pode usar o skipif para rodar somente o teste apropriado para determinada plataforma.

### Xfail

Este Ã© bem interessante porque para o teste marcado com ele passar, na verdade o teste tem que falhar. Confuso, nÃ£o? ğŸ¤”

Primeiramente, Ã© importante salientar que isso Ã© diferente de criar um teste que espera um erro, por exemplo.

Aqui a intenÃ§Ã£o Ã© que o teste de fato falhe. Por isso o nome do marcador Ã©Â _expect fail_Â (esperamos que falhe).

AÂ [documentaÃ§Ã£o](https://docs.pytest.org/en/stable/how-to/skipping.html)Â cita um caso de uso, mas temos um exemplo bem interessante aqui na Trybe: testes de testes.

Em alguns projetos cobramos a escrita de testes. Como fazemos para verificar se os testes que vocÃª escreveu no projeto funcionam? Simples: fornecemos implementaÃ§Ãµes incorretas da funÃ§Ã£o a ser testada e rodamos seu teste em cima de cada implementaÃ§Ã£o incorreta esperando que o teste falhe (usamos oÂ `XFAIL`). Por fim, rodamos o teste em cima de uma implementaÃ§Ã£o correta e esperamos que ele passe. Se o seu testeÂ **_falhar_**Â para as implementaÃ§Ãµes incorretas eÂ **_passar_**Â para a implementaÃ§Ã£o correta, vocÃª pontua no requisito!

###### Fonte: [Curse](https://app.betrybe.com/learn/course/5e938f69-6e32-43b3-9685-c936530fd326/module/3d93d491-e3ed-409f-bdb6-3a5dcd11f8d2/section/18498288-db33-45a4-9189-b7a282d99538/day/eeb316f5-4729-427e-960b-1397a647e5d7/lesson/89ae3ff1-2318-44ad-9ecf-0883335d4ef5)

