[[4 - Raspagem de Dados]]

ğŸ§¼ğŸ§½ Estamos extraindo nossos dados, porÃ©m estes dados contÃ©m algumas â€œsujeirasâ€ que podem atrapalhar em nossas anÃ¡lises. Por exemplo, pare pra olhar o preÃ§o do livro, viu algo diferente? O preÃ§o possui um caractere estranhoÂ `Ã‚Â£26.08`Â antes do seu valor. E a descriÃ§Ã£o do livro que contÃ©m o sufixoÂ `...more`.

Seria conveniente, antes de estruturar e armazenar estes dados, que fizÃ©ssemos uma limpeza neles.

No caso do valor, poderÃ­amos utilizar uma expressÃ£o regular para remover os outros caracteres. O padrÃ£o Ã© conter um sÃ­mbolo de libra, seguido por nÃºmeros, ponto para separar casas decimais e dois nÃºmeros como casas decimais. Essa expressÃ£o regular pode ser feita da seguinte forma:Â `Â£\d+\.\d{2}`.

Agora, para utilizar a expressÃ£o regular que fizemos, podemos substituir o mÃ©todoÂ `getall`Â pelo mÃ©todoÂ `re`, ou o mÃ©todoÂ `get`Â porÂ `re_first`. Ambos, alÃ©m de recuperar valores, aplicarÃ£o a expressÃ£o regular sobre aquele valor.

Vamos primeiro fazer essasÂ _features_, novamente, no arquivo deÂ `teste.py`Â para vermos funcionando. Depois vamos implementÃ¡-las no arquivoÂ `exemplo_scrape.py`:

> teste.py

```python
from parsel import Selector
import requests


response = requests.get("http://books.toscrape.com/")
selector = Selector(text=response.text)
# Extrai todos os preÃ§os da primeira pÃ¡gina
prices = selector.css(".product_price .price_color::text").re(r"Â£\d+\.\d{2}")
print(prices)
```

JÃ¡ para o caso do sufixoÂ `...more`, poderÃ­amos utilizar fatiamento para removÃª-lo. Mas antes Ã© importante verificarmos se o conteÃºdo possui o sufixo, evitando assim perda de conteÃºdo de forma acidental. Vamos ver como isso funciona no arquivoÂ `teste.py`:

> teste.py

```python
from parsel import Selector
import requests


response = requests.get("http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html")
selector = Selector(text=response.text)

# Extrai a descriÃ§Ã£o
description = selector.css("#product_description ~ p::text").get()
print(description)

# "Fatiamos" a descriÃ§Ã£o removendo o sufixo
suffix = "...more"
if description.endswith(suffix):
    description = description[:-len(suffix)]
print(description)
```

Alguns outros exemplos de â€œsujeirasâ€ sÃ£o valores que contÃ©m tabulaÃ§Ãµes, quebras de linha ou conteÃºdo alÃ©m do esperado.

Agora vamos implementar essas funcionalidades no nosso arquivoÂ `exemplo_scrape.py`:

> exemplo_scrape.py

```python
from parsel import Selector
import requests


# URL_BASE = "http://books.toscrape.com/catalogue/"
# Define a primeira pÃ¡gina como prÃ³xima a ter seu conteÃºdo recuperado
# next_page_url = 'page-1.html'
# while next_page_url:
    # Busca o conteÃºdo da prÃ³xima pÃ¡gina
    # response = requests.get(URL_BASE + next_page_url)
    # selector = Selector(text=response.text)
    # Imprime os produtos de uma determinada pÃ¡gina
    # for product in selector.css(".product_pod"):
        # Busca e extrai o tÃ­tulo e  o preÃ§o
        # title = product.css("h3 a::attr(title)").get()
        price = product.css(".product_price .price_color::text").re(r"Â£\d+\.\d{2}")
        # print(title, price)

        # Busca o detalhe de um produto
        # detail_href = product.css("h3 a::attr(href)").get()
        # detail_page_url = URL_BASE + detail_href

        # Baixa o conteÃºdo da pÃ¡gina de detalhes
        # detail_response = requests.get(detail_page_url)
        # detail_selector = Selector(text=detail_response.text)

        # Extrai a descriÃ§Ã£o do produto
        # description = detail_selector.css("#product_description ~ p::text").get()
        suffix = "...more"
        if description.endswith(suffix):
            description = description[:-len(suffix)]
        # print(description)

    # Descobre qual Ã© a prÃ³xima pÃ¡gina
    # next_page_url = selector.css(".next a::attr(href)").get()
```

> ğŸ‘€Â **De olho na dica**: Strings emÂ **Python**Â possuem vÃ¡rios mÃ©todos para ajudarem nesta limpeza, como por exemplo, oÂ `strip`. Para ler a documentaÃ§Ã£o e procurar esses mÃ©todos, executeÂ `help(str)`Â no seu terminal interativo.

## Fatiamento

Estruturas de dados do tipo sequÃªncia, como listas, tuplas e strings, podem ter seus elementos acessados atravÃ©s de um Ã­ndice:

```bash
# Recupera o primeiro elemento
[1, 2, 3][0]  # SaÃ­da: 1
```

Podemos tambÃ©m definir dois Ã­ndices que serÃ£o o valor inicial e final de uma subsequÃªncia da estrutura. Ou trÃªs valores, sendo o Ãºltimo o tamanho do passo que daremos ao percorrer a subsequÃªncia:

```bash
# Quando nÃ£o incluso o valor inicial, iniciaremos do Ã­ndice 0
# e do Ã­ndice 2 em diante, os elementos nÃ£o sÃ£o incluÃ­dos
(1, 2, 3, 4)[:2]  # SaÃ­da: (1, 2)

# Quando omitimos o valor final
# o fatiamento ocorre atÃ© o fim da sequÃªncia
(1, 2, 3, 4)[1:]  # SaÃ­da: (2, 3, 4)

# VÃ¡ do Ã­ndice 3 atÃ© o 7.
# O item no Ã­ndice 7 nÃ£o Ã© incluÃ­do
"palavra"[3:7]  # SaÃ­da: "avra"

# ComeÃ§ando do elemento de Ã­ndice 1, vÃ¡ atÃ© o Ãºltimo,
# saltando de 2 em 2
[1, 2, 3, 4][1::2]  # SaÃ­da: [2, 4]
```

Chamamos esta operaÃ§Ã£o deÂ **fatiamento**. Ela Ã© muito utilizada para obtermos uma subsequÃªncia de uma sequÃªncia.

> âš ï¸Ã€ partir da versÃ£o 3.9 do Python, teremos uma funÃ§Ã£o chamadaÂ `removesuffix`, que Ã© equivalente Ã Â `palavra[:-len(suffix)]`.

## Scrapy

ğŸ•· Uma excelente e poderosa ferramenta para raspagem de dados Ã© aÂ [Scrapy](https://scrapy.org/). Ela possui, em sua implementaÃ§Ã£o, todos os mecanismos citados anteriormente e outros recursos adicionais.

Vale a pena dar uma olhadinha! ğŸ˜‰

###### Fonte: [Curse](https://app.betrybe.com/learn/course/5e938f69-6e32-43b3-9685-c936530fd326/module/3d93d491-e3ed-409f-bdb6-3a5dcd11f8d2/section/61c046bb-0372-49d7-83c1-fe68b9e01d73/day/29e6c74d-baff-46b1-9880-3ce81ab1a33e/lesson/5c3e00f7-1832-4664-a2af-abea65f307cc)

