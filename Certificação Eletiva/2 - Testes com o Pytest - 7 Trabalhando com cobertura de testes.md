[[2 - Testes com o Pytest]]

VocÃª estÃ¡ brilhando! ğŸŒŸ Mas ainda podemos avanÃ§ar na construÃ§Ã£o dos nossos testes, nÃ©?

No exemplo anterior, conseguimos testar muitas partes do nosso cÃ³digo, mas ainda nÃ£o testamos todas as possibilidades. Vamos ver como podemos fazer isso?!

AÂ **cobertura de testes**Â Ã© uma mÃ©trica crucial que nos auxilia a compreender quais partes do cÃ³digo estÃ£o sendo testadas e Ã© fundamental para assegurar que todas essas Ã¡reas sejam testadas.

Ã‰ importante lembrar que a cobertura de testes nÃ£o garante a correÃ§Ã£o do cÃ³digo, mas apenas indica que ele estÃ¡ sendo testado. Mesmo com uma cobertura de 100%, se os testes nÃ£o forem adequados, o cÃ³digo pode nÃ£o cumprir todas as suas funcionalidades corretamente e atÃ© mesmo conter bugs. Portanto, Ã© crucial que os testes sejam bem escritos e cubram todos osÂ **casos de uso**Â do cÃ³digo.

## Instalando o pytest-cov

Para calcular a cobertura de testes do nosso cÃ³digo, serÃ¡ utilizado o pacoteÂ `pytest-cov`. Ele Ã© um dos diversos plugins disponÃ­veis para oÂ `Pytest`Â que nos ajudam a escrever testes melhores.

> **De olho na dica ğŸ‘€:**Â Existem plugins incrÃ­veis para o Pytest! VocÃª pode conferir a lista completa de plugins disponÃ­veisÂ [aqui](https://docs.pytest.org/en/7.3.x/reference/plugin_list.html)Â e aprender como escrever seu prÃ³prio pluginÂ [aqui](https://docs.pytest.org/en/7.3.x/how-to/writing_plugins.html#writing-plugins).

Para instalar oÂ `pytest-cov`, basta executar o comando abaixo:

```bash
pip install pytest-cov==4.0.0
```

## Calculando a cobertura de testes

Para entender o comportamento doÂ `pytest-cov`, considere os seguintes arquivos de cÃ³digo:

```python
# arquivo: analyzer.py
import json


def read_json_file(file_path):
    with open(file_path, "r") as file:
        return json.load(file)


def analyze_json_file(file_path):
    if not file_path.endswith(".json"):
        raise ValueError("O arquivo precisa ser um arquivo JSON.")
    
    data = read_json_file(file_path)
    return (
        f"A pessoa de nome {data['nome']} "
        f"possui {data['idade']} anos de idade."
    )

```

Copiar

```python
# arquivo: tests/test_analyzer.py
from unittest.mock import Mock, patch

import pytest

from analyzer import analyze_json_file, read_json_file


def test_analyze_json_file():
    mock_read_json_file = Mock(
        side_effect=[
            {"nome": "Maria", "idade": 31},
            {"nome": "Agenor", "idade": 86},
        ]
    )
    fake_file_path = "invalid.json"

    with patch("analyzer.read_json_file", mock_read_json_file):
        assert (
            analyze_json_file(fake_file_path)
            == "A pessoa de nome Maria possui 31 anos de idade."
        )
        assert (
            analyze_json_file(fake_file_path)
            == "A pessoa de nome Agenor possui 86 anos de idade."
        )

    mock_read_json_file.assert_called_with(fake_file_path)


def test_analyze_json_file_propagates_exception():
    mock_read_json_file = Mock(side_effect=FileNotFoundError)
    fake_file_path = "invalid.json"

    with patch("analyzer.read_json_file", mock_read_json_file):
        with pytest.raises(FileNotFoundError):
            analyze_json_file(fake_file_path)


def test_read_json_file(tmp_path):
    fake_file_path = tmp_path / "fake.json"
    fake_file_path.touch()

    mock_json = Mock()
    mock_json.load = Mock(return_value={"nome": "Maria", "idade": 31})

    with patch("analyzer.json", mock_json):
        result = read_json_file(fake_file_path)

    assert result == {"nome": "Maria", "idade": 31}

```

> **Relembrando ğŸ§ :**Â A fixtureÂ `tmp_path`Â do Pytest Ã© usada para criar um diretÃ³rio temporÃ¡rio que serÃ¡ excluÃ­do apÃ³s a execuÃ§Ã£o dos testes. Ela fornece um objeto especial do tipoÂ `pathlib.Path`, e por isso o mÃ©todoÂ `.touch()`Â pode ser usado para criar o arquivo â€œfake.jsonâ€.

Para calcular a cobertura de testes, vamos executarÂ `pytest`Â com o argumentoÂ `--cov`:

```bash
pytest --cov
```

ou:

```bash
python3 -m pytest --cov
```

O resultado serÃ¡ algo parecido com isso:

![SaÃ­da do comando `python3 -m pytest --cov`](https://content-assets.betrybe.com/prod/0d956884-61c3-4d1b-bd14-50030e178d6e-Sa%C3%ADda%20do%20comando%20%60python3%20-m%20pytest%20--cov%60.png)
SaÃ­da do comandoÂ `python3 -m pytest --cov`

OÂ `pytest-cov`Â nos mostra a cobertura de execuÃ§Ã£o de cada arquivo do nosso projeto. Nesse caso, hÃ¡ 2 arquivos: oÂ `analyzer.py`Â e oÂ `test_analyzer.py`. OÂ `test_analyzer.py`Â tem 100% de cobertura, pois todas as suas linhas foram executadas durante os testes. PorÃ©m, oÂ `analyzer.py`Â tem apenas 89% de cobertura, pois uma das linhas nÃ£o foi executada. Ã‰ possÃ­vel saber isso porque a colunaÂ `Miss`Â estÃ¡ com o valorÂ `1`.

## Detalhando a cobertura de testes

Como nosso interesse Ã© apenas no arquivoÂ `analyzer.py`, Ã© possÃ­vel executar oÂ `pytest`Â novamente ajustando o argumentoÂ `--cov`Â paraÂ `--cov analyzer`:

Para entender qual linha nÃ£o foi executada no arquivoÂ `analyzer.py`, Ã© possÃ­vel usar o argumentoÂ `--cov-report=term-missing`. Adicionando essas duas alteraÃ§Ãµes, o comando fica assim:

```bash
pytest --cov analyzer --cov-report=term-missing
```

> **Anota aÃ­ ğŸ“:**Â O argumentoÂ `--cov`Â recebe um ou maisÂ **mÃ³dulos ou pacotes**, por isso nÃ£o se coloca oÂ `.py`Â ao final deÂ `analyzer`. Se for passado apenas o nome do pacote (pasta), serÃ¡ calculada a cobertura de todos os arquivos do pacote. JÃ¡ se for passado apenas o nome de um mÃ³dulo (arquivo), o cÃ¡lculo serÃ¡ apenas daquele mÃ³dulo.

O resultado serÃ¡ algo parecido com isso:

![SaÃ­da do comando `pytest --cov analyzer --cov-report=term-missing`](https://content-assets.betrybe.com/prod/0d956884-61c3-4d1b-bd14-50030e178d6e-Sa%C3%ADda%20do%20comando%20%60pytest%20--cov%20analyzer%20--cov-report=term-missing%60.png)
SaÃ­da do comandoÂ `python3 -m pytest --cov analyzer --cov-report=term-missing`Â (ouÂ `pytest --cov analyzer --cov-report=term-missing`)

Antes de avanÃ§ar, Ã© importante destacar alguns pontos:

1. Apesar de o argumentoÂ `--cov analyzer`Â ter sido indicado na linha de comando, nÃ£o hÃ¡ interferÃªncia emÂ _**quais testes sÃ£o executados**_: todos os testes sÃ£o executados normalmente.
2. Agora sabemos a linha que nÃ£o foi executada, por meio da colunaÂ `Missing`Â da tabela! ğŸ‰ Nesse caso, a linha 11 nÃ£o foi executada.

## Aumentando a cobertura de testes

Agora que vocÃª sabe qual linha nÃ£o foi executada, pode escrever um teste que passe por ela! Vamos lÃ¡?! ğŸš€

## Para fixar

## ExercÃ­cio 1

Escreva uma nova funÃ§Ã£o de teste no arquivoÂ `test_analyzer.py`Â que passe pela linha 11 do arquivoÂ `analyzer.py`Â do exemplo, garantindo 100% de cobertura de testes.

Uma possÃ­vel soluÃ§Ã£o para o exercÃ­cio Ã©:

```python
def test_analyze_json_file_raises_exception_when_not_json():
    fake_file_path = "invalid.txt"

    with pytest.raises(
        ValueError, match="O arquivo precisa ser um arquivo JSON."
    ):
        analyze_json_file(fake_file_path)
```

Aqui, vocÃª estÃ¡ testando o caso em que o arquivo nÃ£o Ã© um arquivo JSON. Para isso, foi passado um arquivo com extensÃ£oÂ `.txt`Â para a funÃ§Ã£oÂ `analyze_json_file`. Como esperado, a funÃ§Ã£o lanÃ§ou umÂ `ValueError`Â com a mensagem â€œO arquivo precisa ser um arquivo JSON.â€.

###### Fonte: [Curse](https://app.betrybe.com/learn/course/5e938f69-6e32-43b3-9685-c936530fd326/module/3d93d491-e3ed-409f-bdb6-3a5dcd11f8d2/section/18498288-db33-45a4-9189-b7a282d99538/day/7a9abd0d-1642-4b80-80c8-4c0dfa8e0470/lesson/901b5b23-0ff3-4ca5-ac03-d88154c0a62d)
